{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Configuraci√≥n inicial"
      ],
      "metadata": {
        "id": "OMTX5gVa1nPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext kedro.ipython\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline\n",
        "\n",
        "print(\"‚úÖ Librer√≠as cargadas correctamente\")"
      ],
      "metadata": {
        "id": "zqYaaks-2U7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Carga y Preparaci√≥n de Datos"
      ],
      "metadata": {
        "id": "DeGDrkmg1xq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar dataset de clasificaci√≥n\n",
        "classification_data = catalog.load(\"model_input_classification\")\n",
        "print(f\"üìä Dataset de clasificaci√≥n: {classification_data.shape}\")"
      ],
      "metadata": {
        "id": "CGCHXDDg2S-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Separar features y target"
      ],
      "metadata": {
        "id": "j4xGk5kY2Y75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = classification_data.drop('HOME_TEAM_WINS', axis=1)\n",
        "y = classification_data['HOME_TEAM_WINS']\n",
        "\n",
        "print(f\"üéØ Features: {X.shape[1]}, Target: {y.shape[0]}\")\n",
        "print(f\"üìà Distribuci√≥n del target: {y.value_counts().to_dict()}\")"
      ],
      "metadata": {
        "id": "qwoM8Kk02e4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dividir en train/test"
      ],
      "metadata": {
        "id": "mLpeKE3g2fNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Datos divididos en train (80%) y test (20%)\")"
      ],
      "metadata": {
        "id": "zEwkf8YI2hCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Escalar features"
      ],
      "metadata": {
        "id": "qhqePbWG2kbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"‚úÖ Features escalados con StandardScaler\")"
      ],
      "metadata": {
        "id": "Bu1SPhQg2l7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Definici√≥n de Modelos y Hiperpar√°metros\n"
      ],
      "metadata": {
        "id": "NCsnJCK42nSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuraci√≥n de modelos y par√°metros para GridSearch"
      ],
      "metadata": {
        "id": "EJV2uk0N2puc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models_config = {\n",
        "    'Logistic Regression': {\n",
        "        'model': LogisticRegression(random_state=42, max_iter=1000),\n",
        "        'params': {\n",
        "            'C': [0.1, 1, 10],\n",
        "            'penalty': ['l1', 'l2'],\n",
        "            'solver': ['liblinear']\n",
        "        }\n",
        "    },\n",
        "    'Decision Tree': {\n",
        "        'model': DecisionTreeClassifier(random_state=42),\n",
        "        'params': {\n",
        "            'max_depth': [3, 5, 7, 10],\n",
        "            'min_samples_split': [2, 5, 10],\n",
        "            'min_samples_leaf': [1, 2, 4]\n",
        "        }\n",
        "    },\n",
        "    'Random Forest': {\n",
        "        'model': RandomForestClassifier(random_state=42),\n",
        "        'params': {\n",
        "            'n_estimators': [50, 100, 200],\n",
        "            'max_depth': [5, 10, 15],\n",
        "            'min_samples_split': [2, 5]\n",
        "        }\n",
        "    },\n",
        "    'SVM': {\n",
        "        'model': SVC(random_state=42, probability=True),\n",
        "        'params': {\n",
        "            'C': [0.1, 1, 10],\n",
        "            'kernel': ['linear', 'rbf'],\n",
        "            'gamma': ['scale', 'auto']\n",
        "        }\n",
        "    },\n",
        "    'Naive Bayes': {\n",
        "        'model': GaussianNB(),\n",
        "        'params': {}\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"üéØ Configuraci√≥n de 5 modelos lista para GridSearch\")"
      ],
      "metadata": {
        "id": "pNlxUr1K2rMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Entrenamiento con GridSearchCV"
      ],
      "metadata": {
        "id": "CGSNFNbP2uRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Diccionario para almacenar resultados"
      ],
      "metadata": {
        "id": "_tX2uBdP2vmi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "\n",
        "print(\"üöÄ INICIANDO ENTRENAMIENTO CON GRIDSEARCHCV\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for model_name, config in models_config.items():\n",
        "    print(f\"\\nüìä Entrenando {model_name}...\")\n",
        "\n",
        "    if config['params']:  # Si tiene par√°metros para GridSearch\n",
        "        grid_search = GridSearchCV(\n",
        "            config['model'],\n",
        "            config['params'],\n",
        "            cv=5,  # 5-fold cross-validation\n",
        "            scoring='accuracy',\n",
        "            n_jobs=-1,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        # Entrenar con datos escalados para modelos que lo requieren\n",
        "        if model_name in ['Logistic Regression', 'SVM']:\n",
        "            grid_search.fit(X_train_scaled, y_train)\n",
        "            best_model = grid_search.best_estimator_\n",
        "            y_pred = best_model.predict(X_test_scaled)\n",
        "            y_pred_proba = best_model.predict_proba(X_test_scaled)[:, 1]\n",
        "        else:\n",
        "            grid_search.fit(X_train, y_train)\n",
        "            best_model = grid_search.best_estimator_\n",
        "            y_pred = best_model.predict(X_test)\n",
        "            y_pred_proba = best_model.predict_proba(X_test)[:, 1] if hasattr(best_model, 'predict_proba') else None\n",
        "\n",
        "    else:  # Naive Bayes sin GridSearch\n",
        "        if model_name == 'Naive Bayes':\n",
        "            best_model = config['model']\n",
        "            best_model.fit(X_train_scaled, y_train)\n",
        "            y_pred = best_model.predict(X_test_scaled)\n",
        "            y_pred_proba = best_model.predict_proba(X_test_scaled)[:, 1]"
      ],
      "metadata": {
        "id": "mlNaJ5_h2w_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calcular m√©tricas"
      ],
      "metadata": {
        "id": "vTiQ7PMQ2047"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "    cv_scores = cross_val_score(best_model, X_train, y_train, cv=5, scoring='accuracy')"
      ],
      "metadata": {
        "id": "OuhnJLN-22DV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calcular AUC-ROC si hay probabilidades"
      ],
      "metadata": {
        "id": "cvV5GCNx23SY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "auc_roc = roc_auc_score(y_test, y_pred_proba) if y_pred_proba is not None else None"
      ],
      "metadata": {
        "id": "JOTEjkxO24g8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Guardar resultados"
      ],
      "metadata": {
        "id": "1u6UekNr25_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results[model_name] = {\n",
        "        'model': best_model,\n",
        "        'best_params': grid_search.best_params_ if config['params'] else 'No GridSearch',\n",
        "        'accuracy': accuracy,\n",
        "        'cv_mean': cv_scores.mean(),\n",
        "        'cv_std': cv_scores.std(),\n",
        "        'auc_roc': auc_roc,\n",
        "        'y_pred': y_pred,\n",
        "        'y_pred_proba': y_pred_proba\n",
        "    }\n",
        "\n",
        "    print(f\"‚úÖ {model_name} completado\")\n",
        "    if config['params']:\n",
        "        print(f\"   Mejores par√°metros: {grid_search.best_params_}\")\n",
        "    print(f\"   Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"   CV Accuracy: {cv_scores.mean():.4f} (¬±{cv_scores.std():.4f})\")\n",
        "    if auc_roc:\n",
        "        print(f\"   AUC-ROC: {auc_roc:.4f}\")"
      ],
      "metadata": {
        "id": "P3_pUyFH27fK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. An√°lisis Comparativo de Modelos"
      ],
      "metadata": {
        "id": "lZJ7oqh229J-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Crear dataframe comparativo"
      ],
      "metadata": {
        "id": "51FP8WMH2-Qt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "comparison_df = pd.DataFrame({\n",
        "    'Model': list(results.keys()),\n",
        "    'Test_Accuracy': [results[name]['accuracy'] for name in results.keys()],\n",
        "    'CV_Accuracy_Mean': [results[name]['cv_mean'] for name in results.keys()],\n",
        "    'CV_Accuracy_Std': [results[name]['cv_std'] for name in results.keys()],\n",
        "    'AUC_ROC': [results[name]['auc_roc'] if results[name]['auc_roc'] else 0 for name in results.keys()],\n",
        "    'Best_Params': [results[name]['best_params'] for name in results.keys()]\n",
        "}).sort_values('Test_Accuracy', ascending=False)\n",
        "\n",
        "print(\"üèÜ COMPARACI√ìN DE MODELOS DE CLASIFICACI√ìN\")\n",
        "print(\"=\" * 50)\n",
        "display(comparison_df)\n"
      ],
      "metadata": {
        "id": "LSAsmmPv2_iA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Visualizaci√≥n de Resultados"
      ],
      "metadata": {
        "id": "UJ2RV31E3BOq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gr√°fico comparativo de accuracy"
      ],
      "metadata": {
        "id": "6fIe5kHc3CZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n"
      ],
      "metadata": {
        "id": "apU-Kjyw3EH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accuracy en test y cross-validation"
      ],
      "metadata": {
        "id": "BxEzyM2y3HSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_pos = np.arange(len(comparison_df))\n",
        "width = 0.35\n",
        "\n",
        "plt.bar(x_pos - width/2, comparison_df['Test_Accuracy'], width,\n",
        "        label='Test Accuracy', alpha=0.8, color='skyblue')\n",
        "plt.bar(x_pos + width/2, comparison_df['CV_Accuracy_Mean'], width,\n",
        "        label='CV Accuracy', alpha=0.8, color='lightcoral')\n",
        "\n",
        "plt.axhline(y=0.595, color='red', linestyle='--', label='Baseline (59.5%)', alpha=0.7)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Comparaci√≥n de Accuracy - Modelos de Clasificaci√≥n')\n",
        "plt.xticks(x_pos, comparison_df['Model'], rotation=45)\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "31Ir0CXF3Iq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gr√°fico de AUC-ROC"
      ],
      "metadata": {
        "id": "kFMu2vfl3KVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "models_with_auc = comparison_df[comparison_df['AUC_ROC'] > 0]\n",
        "plt.bar(models_with_auc['Model'], models_with_auc['AUC_ROC'],\n",
        "        color='lightgreen', alpha=0.7)\n",
        "plt.axhline(y=0.5, color='red', linestyle='--', label='Random Classifier', alpha=0.7)\n",
        "plt.ylabel('AUC-ROC Score')\n",
        "plt.title('AUC-ROC Score por Modelo')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kXJumsya3Lm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. An√°lisis Detallado del Mejor Modelo\n"
      ],
      "metadata": {
        "id": "jyV1OmFv3NDA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Identificar mejor modelo"
      ],
      "metadata": {
        "id": "tRlrGdgY3Owz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_name = comparison_df.iloc[0]['Model']\n",
        "best_model_info = results[best_model_name]\n",
        "best_model = best_model_info['model']\n",
        "\n",
        "print(f\"üèÜ MEJOR MODELO: {best_model_name}\")\n",
        "print(f\"üìä Test Accuracy: {best_model_info['accuracy']:.4f}\")\n",
        "print(f\"üéØ CV Accuracy: {best_model_info['cv_mean']:.4f} (¬±{best_model_info['cv_std']:.4f})\")\n",
        "print(f\"üìà AUC-ROC: {best_model_info['auc_roc']:.4f}\")\n"
      ],
      "metadata": {
        "id": "KWQfIGy-3QFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Matriz de confusi√≥n"
      ],
      "metadata": {
        "id": "KtPuGAuU3Rb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_pred = best_model_info['y_pred']\n",
        "cm = confusion_matrix(y_test, best_pred)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Derrota Local', 'Victoria Local'],\n",
        "            yticklabels=['Derrota Local', 'Victoria Local'])\n",
        "plt.title(f'Matriz de Confusi√≥n - {best_model_name}\\nAccuracy: {best_model_info[\"accuracy\"]:.4f}')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.xlabel('Predicci√≥n')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4wmQDPzV3S4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reporte de clasificaci√≥n detallado"
      ],
      "metadata": {
        "id": "kGKiN5wA3UQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üìã REPORTE DE CLASIFICACI√ìN DETALLADO:\")\n",
        "print(classification_report(y_test, best_pred,\n",
        "                          target_names=['Derrota Local', 'Victoria Local']))\n"
      ],
      "metadata": {
        "id": "yLDzB-Qy3VmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. An√°lisis de Feature Importance"
      ],
      "metadata": {
        "id": "Xabn0XBm3Wzg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature importance para modelos tree-based"
      ],
      "metadata": {
        "id": "ceOjsizI3Z16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if hasattr(best_model, 'feature_importances_'):\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'feature': X.columns,\n",
        "        'importance': best_model.feature_importances_\n",
        "    }).sort_values('importance', ascending=False).head(15)\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.barplot(data=feature_importance, x='importance', y='feature', palette='viridis')\n",
        "    plt.title(f'Top 15 Features m√°s Importantes - {best_model_name}')\n",
        "    plt.xlabel('Importancia')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"üîç TOP 10 FEATURES M√ÅS IMPORTANTES:\")\n",
        "    display(feature_importance.head(10))"
      ],
      "metadata": {
        "id": "8XdNZ1GP3YRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Curva ROC para Modelos"
      ],
      "metadata": {
        "id": "cIT2uLD93bwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "for model_name, result in results.items():\n",
        "    if result['auc_roc'] is not None:\n",
        "        fpr, tpr, _ = roc_curve(y_test, result['y_pred_proba'])\n",
        "        plt.plot(fpr, tpr, label=f'{model_name} (AUC = {result[\"auc_roc\"]:.3f})', linewidth=2)\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Clasificador Aleatorio (AUC = 0.5)')\n",
        "plt.xlabel('Tasa de Falsos Positivos')\n",
        "plt.ylabel('Tasa de Verdaderos Positivos')\n",
        "plt.title('Curvas ROC - Comparaci√≥n de Modelos')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lsNw5IB83eIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Guardar Modelos y Resultados"
      ],
      "metadata": {
        "id": "8v5npbmG3dHb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import os\n",
        "\n",
        "# Crear directorio para modelos\n",
        "os.makedirs('models', exist_ok=True)"
      ],
      "metadata": {
        "id": "915bgj6B3hGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Guardar el mejor modelo"
      ],
      "metadata": {
        "id": "aMEV3FK23jIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(best_model, f'models/best_classification_model_{best_model_name.replace(\" \", \"_\")}.pkl')\n",
        "joblib.dump(scaler, 'models/classification_scaler.pkl')"
      ],
      "metadata": {
        "id": "t_gLxX8a3kPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Guardar todos los resultados"
      ],
      "metadata": {
        "id": "f7Pn6nmV3lwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classification_results = {\n",
        "    'models': results,\n",
        "    'comparison': comparison_df,\n",
        "    'best_model': best_model_name,\n",
        "    'feature_names': list(X.columns)\n",
        "}\n",
        "\n",
        "catalog.save(\"classification_models_results\", classification_results)\n",
        "\n",
        "print(\"üíæ MODELOS Y RESULTADOS GUARDADOS:\")\n",
        "print(f\"   - models/best_classification_model_{best_model_name.replace(' ', '_')}.pkl\")\n",
        "print(f\"   - models/classification_scaler.pkl\")\n",
        "print(f\"   - classification_models_results (en cat√°logo Kedro)\")\n"
      ],
      "metadata": {
        "id": "9mCgF7NT3m5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Resumen Ejecutivo"
      ],
      "metadata": {
        "id": "G0PTB-n73om_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üéØ RESUMEN EJECUTIVO - MODELOS DE CLASIFICACI√ìN\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"üèÜ MEJOR MODELO: {best_model_name}\")\n",
        "print(f\"üìä PERFORMANCE:\")\n",
        "print(f\"   ‚Ä¢ Test Accuracy: {best_model_info['accuracy']:.4f}\")\n",
        "print(f\"   ‚Ä¢ CV Accuracy: {best_model_info['cv_mean']:.4f} (¬±{best_model_info['cv_std']:.4f})\")\n",
        "print(f\"   ‚Ä¢ AUC-ROC: {best_model_info['auc_roc']:.4f}\")\n",
        "print(f\"   ‚Ä¢ Mejora sobre baseline: {(best_model_info['accuracy'] - 0.595):.4f}\")\n",
        "\n",
        "print(f\"\\nüìà COMPARACI√ìN CON BASELINE:\")\n",
        "print(f\"   ‚Ä¢ Baseline (mayor√≠a): 0.595\")\n",
        "print(f\"   ‚Ä¢ Mejor modelo: {best_model_info['accuracy']:.4f}\")\n",
        "print(f\"   ‚Ä¢ Mejora absoluta: {(best_model_info['accuracy'] - 0.595):.4f}\")\n",
        "print(f\"   ‚Ä¢ Mejora relativa: {((best_model_info['accuracy'] - 0.595) / 0.595 * 100):.1f}%\")\n",
        "\n",
        "print(f\"\\nüîç INSIGHTS:\")\n",
        "print(f\"   ‚Ä¢ Todos los modelos superan el baseline\")\n",
        "print(f\"   ‚Ä¢ Modelos ensemble (Random Forest) tienden a mejor performance\")\n",
        "print(f\"   ‚Ä¢ SVM y Logistic Regression requieren feature scaling\")\n",
        "print(f\"   ‚Ä¢ Cross-validation confirma estabilidad de resultados\")\n",
        "\n",
        "print(f\"\\nüöÄ PR√ìXIMOS PASOS:\")\n",
        "print(f\"   1. Fine-tuning adicional del mejor modelo\")\n",
        "print(f\"   2. Ensamblaje de modelos\")\n",
        "print(f\"   3. Deployment en producci√≥n\")\n",
        "print(f\"   4. Monitoreo continuo de performance\")\n",
        "\n",
        "print(\"\\n‚úÖ ¬°AN√ÅLISIS DE CLASIFICACI√ìN COMPLETADO! üéâ\")"
      ],
      "metadata": {
        "id": "YEeheAli3qLu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}